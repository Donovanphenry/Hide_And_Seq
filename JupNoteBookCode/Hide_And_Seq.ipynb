{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "PromoterPredictor_DataFrames.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkq4nAmXpDy2"
      },
      "source": [
        "## Installing Proper Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yys5AHCepDy7"
      },
      "source": [
        "!pip install Bio\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# download data\n",
        "!wget --user=ftp ftp://ccg.epfl.ch/epd/current/epd_16K.seq\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMHahNnGpDy8"
      },
      "source": [
        "## Building DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqsCCk96pDy8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d57ebaa-9f8b-4d71-8bef-4eb09c03f776"
      },
      "source": [
        "from Bio import SeqIO\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "\n",
        "# Initializing lists that will contain info about each record\n",
        "accessIDs = []\n",
        "DNA_Sequences = []\n",
        "sequence_lengths = []\n",
        "parsed_subsequences = []\n",
        "\n",
        "# All DNA sequences of the human genome are 16,000 characters long (Hence epd_16K)\n",
        "# if using epd_16K. If using epd_seq, then change the sequence_length variable\n",
        "# to 600\n",
        "sequence_length = 16000\n",
        "\n",
        "test = 1\n",
        "\n",
        "# Loop through all records parsed by SeqIO.\n",
        "#\n",
        "# \") Hs\" on the description line means that\n",
        "# we've found a Homo sapien DNA sequence, so\n",
        "# add the appropriate properties of seq_record\n",
        "# to the appropriate arrays. This is our way\n",
        "# to filter out non-homosapien sequences\n",
        "for seq_record in SeqIO.parse('epd_16K.seq', 'fasta'):\n",
        "  if seq_record.seq.find('N') == -1 and seq_record.description.find(') Hs') != -1:\n",
        "    accessIDs.append(seq_record.id)\n",
        "    DNA_Sequences.append(seq_record.seq)\n",
        "    sequence_lengths.append(len(seq_record))\n",
        "\n",
        "print(\"Number of sequences: \" + str(len(DNA_Sequences)))\n",
        "\n",
        "# Defining rows of PSFM and initializing all frequencies to 0\n",
        "adenine_frequencies = np.zeros(sequence_length)\n",
        "guanine_frequencies = np.zeros(sequence_length)\n",
        "thymine_frequencies = np.zeros(sequence_length)\n",
        "cytosine_frequencies = np.zeros(sequence_length)\n",
        "other_frequency = np.zeros(sequence_length)\n",
        "\n",
        "# Loop through all the DNA sequences in the DNA_Sequence list.\n",
        "# For each sequence, check if the nucleobase (character) at \n",
        "# postition sequence_index is adenine, guanine, thymine, or cytosine.\n",
        "# If it's any of those, then increment the count at that list's index.\n",
        "for sequence in DNA_Sequences:\n",
        "\n",
        "  # Randomly generating where the window begins,\n",
        "  # and since we want each sequence to be 6,000 chars\n",
        "  # long, we add 6,000 to the rng splicedStart, giving\n",
        "  # us the spliced end. Then, since we moved the start of\n",
        "  # the sequence up by a number of splicedStart, to get where\n",
        "  # the promoter is in relation to that new start, we can\n",
        "  # subtract splicedStart from 10,000\n",
        "  # i.e. promoterindex = 10,000 - splicedStart\n",
        "  splicedStart = random.randint(5000, 9000)\n",
        "  splicedEnd = splicedStart + 6000\n",
        "  sub_sequence = sequence[splicedStart : splicedEnd]\n",
        "  promoterIndex = 10000 - splicedStart\n",
        "\n",
        "  # OneHot on subsequence string to create list of lists for features\n",
        "  parsed_str = str(sub_sequence).replace('A', '1000').replace('G', '0100').replace('T', '0010').replace('C', '0001')\n",
        "\n",
        "  one_hot_sequence = [int(i) for i in parsed_str]\n",
        "  one_hot_sequence = np.asarray(one_hot_sequence)\n",
        "  # one_hot_sequence = np.asarray(one_hot_sequence, dtype = 'int32')\n",
        "  # one_hot_sequence = pd.Series(data = one_hot_sequence)\n",
        "\n",
        "  if test == 1:\n",
        "    test = 0\n",
        "    print('OHS Type: ', type(one_hot_sequence))\n",
        "  \n",
        "  pair = (sub_sequence, one_hot_sequence, promoterIndex, splicedStart, splicedEnd)\n",
        "  parsed_subsequences.append(pair)\n",
        "  \n",
        "\n",
        "  # Reset where the index is in the\n",
        "  # sequence string\n",
        "  sequence_index = 0\n",
        "\n",
        "  for nucleobase in sequence:\n",
        "    if nucleobase == 'A':\n",
        "      adenine_frequencies[sequence_index] += 1\n",
        "    elif nucleobase == 'G':\n",
        "      guanine_frequencies[sequence_index] += 1\n",
        "    elif nucleobase == 'T':\n",
        "      thymine_frequencies[sequence_index] += 1\n",
        "    elif nucleobase == 'C':\n",
        "      cytosine_frequencies[sequence_index] += 1\n",
        "    else:\n",
        "      other_frequency[sequence_index] += 1\n",
        "\n",
        "    sequence_index += 1\n",
        "\n",
        "subsequence_df = pd.DataFrame(parsed_subsequences, columns = ['Sub-Sequences', 'One-Hot', 'PromoterIndex', 'SequenceStart', 'SequenceEnd'])\n",
        "\n",
        "# In the above loop, we calculated how many occurences M of a particular nucelobase N\n",
        "# at some sequence index I. In this loop, we divide each number of occurences by the total\n",
        "# number of possible occurences there could be, which would be the number of records\n",
        "# because each record is guaranteed to have a nucleobase at character I in the human\n",
        "# DNA sequence. I.e.\n",
        "# P(sequence[i] == N) == (# of nucleobases N found at index i) / (# of possible nucleobases N at index i)\n",
        "for i in range(sequence_length):\n",
        "  adenine_frequencies[i] = (adenine_frequencies[i] / len(DNA_Sequences)) * 100\n",
        "  guanine_frequencies[i] = (guanine_frequencies[i] / len(DNA_Sequences)) * 100\n",
        "  thymine_frequencies[i] = (thymine_frequencies[i] / len(DNA_Sequences)) * 100\n",
        "  cytosine_frequencies[i] = (cytosine_frequencies[i] / len(DNA_Sequences)) * 100\n",
        "\n",
        "\n",
        "# Defining the series that will be fed into the pandas Data Frame, based off the lists defined above\n",
        "records_df = pd.DataFrame({'IDs': accessIDs, 'Sequences': DNA_Sequences, 'Lengths': sequence_lengths},\n",
        "                          columns = ['IDs', 'Sequences', 'Lengths'])\n",
        "\n",
        "# Defining the data frame for the Position Specific Frequency Matrix (PSFM)\n",
        "frequency_df = pd.DataFrame({'Adenine Frequencies': adenine_frequencies, 'Guanine Frequencies': guanine_frequencies, 'Thymine Frequencies': thymine_frequencies, 'Cytosine Frequencies': cytosine_frequencies},\n",
        "                            columns = ['Adenine Frequencies', 'Guanine Frequencies', 'Thymine Frequencies', 'Cytosine Frequencies'])"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 1837\n",
            "OHS Type:  <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TOg6thKpV2m"
      },
      "source": [
        "# RECORDS DATAFRAME INFORMATION\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eREoALEnpDy8"
      },
      "source": [
        "## Printing records dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2klEXodpDy9"
      },
      "source": [
        "records_df.head(n=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JonuT2z1pbD-"
      },
      "source": [
        "# FREQUENCY DATAFRAME INFORMATION\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi6CQFyPpDy9"
      },
      "source": [
        "## Printing frequency data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALOXcy8ypDy9"
      },
      "source": [
        "frequency_df.head(n=10500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKO51jbqpDy9"
      },
      "source": [
        "## Describing Frequency data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVSEMlz0pDy-"
      },
      "source": [
        "frequency_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z8voM9ypDy-"
      },
      "source": [
        "## Plotting frequency graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtrSvNRApDy-"
      },
      "source": [
        "plt.figure()\n",
        "frequency_df.plot(subplots=True, figsize=(25, 15), xlabel = \"Position in DNA Sequence\", ylabel = \"P(nucleobase)\", title = \"Position Specific Frequency Graph\", ylim = (0, 55))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9SG01vzpeXK"
      },
      "source": [
        "# SUBSEQUENCE DATAFRAME INFORMATION\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNHchQiVkBXU"
      },
      "source": [
        "## Printing Subsequence DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYBxRimrkEDQ"
      },
      "source": [
        "subsequence_df.head(n=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzMocqX1pnFq"
      },
      "source": [
        "## Describing the subsequence dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VWYzxIcpl7V"
      },
      "source": [
        "print('Index frequencies:')\r\n",
        "print(subsequence_df['PromoterIndex'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIY12V_tprpO"
      },
      "source": [
        "# Histogram plot of subsequence dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdi0X2rLpyFH"
      },
      "source": [
        "plt.figure()\r\n",
        "subsequence_df['PromoterIndex'].plot.hist(histtype = 'bar', bins = 6000, figsize = (25, 5), title = 'Promoter Indices')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_pRtiCTp03M"
      },
      "source": [
        "## Density plot of subsequence dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03iJ57Mbp64s"
      },
      "source": [
        "plt.figure()\r\n",
        "subsequence_df['PromoterIndex'].plot.density(figsize = (25, 5), title = 'Promoter Indices')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdT4il14lv3o"
      },
      "source": [
        "## Printing one-hot features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3lqGBuSl0lA",
        "outputId": "221b060e-05be-4690-d41f-c6b3612e5a52"
      },
      "source": [
        "print(subsequence_df['One-Hot'].head(n = 10))\r\n",
        "\r\n",
        "print('Type: ', type(subsequence_df['One-Hot']))"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...\n",
            "1    [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, ...\n",
            "2    [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, ...\n",
            "3    [0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, ...\n",
            "4    [0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, ...\n",
            "5    [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, ...\n",
            "6    [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, ...\n",
            "7    [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, ...\n",
            "8    [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, ...\n",
            "9    [0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, ...\n",
            "Name: One-Hot, dtype: object\n",
            "Type:  <class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7abLJ8aiVE3"
      },
      "source": [
        "## Arranging features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Hj-l_87iU0T",
        "outputId": "2d763456-a37b-4942-eb13-3db4a35be730"
      },
      "source": [
        "X = subsequence_df['One-Hot'].to_numpy()\r\n",
        "y = subsequence_df['PromoterIndex'].to_numpy()\r\n",
        "\r\n",
        "print(\"Features: \\n\")\r\n",
        "print(X)\r\n",
        "print(\"\\nFeatures type: \", type(X))\r\n",
        "\r\n",
        "print(\"Labels: \\n\")\r\n",
        "print(y)\r\n",
        "print(\"\\n\")"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features: \n",
            "\n",
            "[array([0, 1, 0, ..., 1, 0, 0], dtype=int32)\n",
            " array([0, 0, 0, ..., 0, 0, 1], dtype=int32)\n",
            " array([1, 0, 0, ..., 0, 0, 1], dtype=int32) ...\n",
            " array([0, 0, 0, ..., 0, 0, 1], dtype=int32)\n",
            " array([0, 0, 0, ..., 0, 1, 0], dtype=int32)\n",
            " array([0, 1, 0, ..., 0, 1, 0], dtype=int32)]\n",
            "\n",
            "Features type:  <class 'numpy.ndarray'>\n",
            "Labels: \n",
            "\n",
            "[1739 2694 2764 ... 4746 1768 1030]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd2gt-3Ug-Fx"
      },
      "source": [
        "## PyTorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F23XyAeTg_6L",
        "outputId": "f1ab9668-39c3-4357-e481-efcd81167b7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "import torch\r\n",
        "from torch.utils.data import Dataset, random_split\r\n",
        "\r\n",
        "class Sequences(Dataset):\r\n",
        "    def __init__(self, X, y):\r\n",
        "        self.sequences = torch.from_numpy(X) # convert numpy arrays to torch tensors\r\n",
        "        self.labels = torch.from_numpy(y)\r\n",
        "\r\n",
        "        self.sequences = self.sequences.unsqueeze(1) # add extra dimension for torch\r\n",
        "        self.labels = self.labels.unsqueeze(1)\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        assert len(self.sequences) == len(self.labels) # ensure 1-to-1 correspondence\r\n",
        "        return len(self.labels)\r\n",
        "\r\n",
        "    def __getitem__(self, i):\r\n",
        "        return self.sequences[i], self.labels[i] # return X, y pair\r\n",
        "\r\n",
        "data = Sequences(X, y)\r\n",
        "trainCount = int(0.8 * len(data)) # percent of our data for train\r\n",
        "train, test = random_split(data, [trainCount, len(data) - trainCount])"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-212-058b05409fa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# return X, y pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mtrainCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# percent of our data for train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrainCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrainCount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-212-058b05409fa5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert numpy arrays to torch tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
          ]
        }
      ]
    }
  ]
}